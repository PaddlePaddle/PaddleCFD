hydra:
  run:
    # dynamic output directory according to running time and override name
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job:
    name: ${mode} # name of logfile
    chdir: false # keep current working direcotry unchaned
  sweep:
    # output directory for multirun
    dir: ${hydra.run.dir}
    subdir: ./

# Setting
mode: "train"
seed: 2024
process: "interpolation"
# process: "dyffusion"
output_dir: ${hydra:run.dir}

DATA:
  root_data_dir: "./data/"
  dataset:
    physical_system: 'navier-stokes'
    window: 1
    horizon: 16
    multi_horizon: true
    num_trajectories: null
  dataloader:
    batch_size:
      train: 32
      val: 4
      test: 1
    num_workers: 0
    drop_last: false
  num_test_obstacles: 1
  test_out_of_distribution: false

INTERPOLATION:
  window: 1
  horizon: 16
  stack_window_to_channel_dim: true
  num_predictions: 20
  prediction_inputs_noise: 0.0
  MODEL:
    model_name: SimpleUnet
    input_channels: 3
    output_channels: 3
    spatial_channels: [221, 42]
    num_cond_channels: 2
    dim: 64
    input_dropout: 0.0
    dropout: 0.15
    upsample_dims: [256, 256]
    outer_sample_mode: bilinear
    with_time_emb: true
  loss_fn: "mse"
  ckpt_no_suffix: null

FORECASTING:
  lass_name: DYffusion
  window: 1
  horizon: 16
  stack_window_to_channel_dim: true
  num_timesteps: 16
  prediction_inputs_noise: 0.0
  lambda_rec_base: 0.5
  lambda_rec_fb: 0.5
  forward_cond: "none"
  pred_timesteps: null
  num_predictions: 20
  MODEL:
    model_name: SimpleUnet
    input_channels: 3
    output_channels: 3
    spatial_channels: [221, 42]
    num_cond_channels: 2
    dim: 64
    input_dropout: 0.0
    dropout: 0.15
    upsample_dims: [256, 256]
    outer_sample_mode: bilinear
    with_time_emb: true
  loss_fn: "l1"
  ckpt_no_suffix: null

SAMPLING:
  num_timesteps: 16
  time_encoding: "dynamics"
  schedule: before_t1_only
  addl_interp_steps: 0
  addl_interp_steps_fac: 0
  interp_before_t1: true
  enable_interp_dropout: true
  sampling_type: cold
  sampling_schedule: null
  refine_interm_preds: true
  use_cold_sampling_for_last_step: false
  log_every_t: null
  pred_timesteps: null

TRAIN:
  epochs: 200
  accumulate_steps: 2
  save_freq: 10
  batch_size: ${DATA.dataloader.batch_size.train}
  optim:
    name: "AdamW"
    learning_rate: 0.0003
    beta1: 0.9
    beta2: 0.99
    epsilon: 1e-08
    weight_decay: 0.0001
    grad_clip: ["norm", 1.0]
  metric_fns: ["mse", "crps", "ssr"]

EVAL:
  batch_size: ${DATA.dataloader.batch_size.val}
  ema:  # EMA
    use_ema: false
    decay: 0.9999
  enable_infer_dropout: true
  prediction_horizon: 16
  prediction_num_predictions: 50
  autoregressive_steps: 0
  verbose: false
  save_dir: ${output_dir}
  metric_fns: ["mse", "ssr"]
  enable_ar: false
  calc_ensemble_metrics: true
  calc_batch_metrics: true
  visual_metrics: true
