# PP-FNO: A surrogate model for super-large 3D CFD simulations

## Dataset

PP-FNO is a data-driven model, where the data is generated by CFD (at present CFD with RANS model). PP-FNO learns to map geometry (CFD computation domain) to cell information (CFD results, such as pressure, wall-shear stress, etc).

#### Data format
- The training data of PP-FNO is extracted from CFD result files:
  - Original CFD files
    ```
    Star CCM+: case.csv (CFD results) + case.stl (Geometry) + case.json (cfd params)
    ```
    
    The format of the original CFD files (case.csv) is as follows. With the following csv file, the train dataset (transformed dataset) can be extracted with `trainDataPreprocess.py`.  
    
    | Pressure (Pa) | Wall Shear Stress[i] (Pa) | Wall Shear Stress[j] (Pa) | Wall Shear Stress[k] (Pa) | Area[i] (m^2) | Area[j] (m^2) | Area[k] (m^2) | X (m) | Y (m) | Z (m) |
    | ------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- |
    | | | | | | | | | | |
    

  - Transformed dataset (2 cases)

    ```
    dataset/
        - 0001_case001 (empty dir)
        - 0002_case002 (empty dir)
        - area_0001.npy
        - area_0002.npy
        - centroid_0001.npy
        - centroid_0002.npy
        - df_0001.npy
        - df_0002.npy
        - info_0001.npy
        - info_0002.npy
        - normal_0001.npy
        - normal_0002.npy
        - pressure_0001.npy
        - pressure_0002.npy
        - wallshearstress_0001.npy
        - wallshearstress_0002.npy
        - area_bounds.txt
        - global_bounds.txt
        - info_bounds.txt
        - train_pressure_mean_std.txt
        - train_wallshearstress_mean_std.txt

    ```
#### Dataset generation
- Download the example dataset here:
  ```
  # use ppcfd inherent tools
  import ppcfd.dara.download as pp_download
  pp_download(
    urls: List[str],
    cache_dir: Optional[Path] = None,
    force_redownload: bool = False,
    use_parallel: bool = False,
    max_workers: int = 4,
  )
  ```

  ```
  # use command line tools
  curl https://paddle-org.bj.bcebos.com/paddlecfd/datasets/ppfno/PP-FNO-Dataset-example.zip --output PP-FNO-Dataset-example.zip
  ```

- Generate your own dataset with ppcfd.data.parser module with corresponding CFD results files.
    ```
    import ppcfd.dara.parser as pp_parser

    pp_parser.H5MatTransition(file_path, save_path, save_data=True)
    pp_parser.MshTransition(file_path, save_path, save_data=True)

    ```
## Conda Environment (Only for ppfno)
As there are some customed operators in the python envs of the model, base image and conda env are provided to simplify the env preparation.

```
# pull the base image
docker pull ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddle:3.0.0-gpu-cuda11.8-cudnn8.6-trt8.5

# run the container
nvidia-docker run --name pp-fno -v /home/PaddleCFD:/home/PaddleCFD --network=host -it --shm-size 64g ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddle:3.0.0-gpu-cuda11.8-cudnn8.6-trt8.5 /bin/bash
```

```
# download conda env package
curl https://paddle-org.bj.bcebos.com/paddlecfd/envs/paddle-open3d-20250530.tar.gz --output paddle-open3d.tar.gz
```
```
# unpack conda env to mimiconda3/envs
cd ~/mimiconda3/envs
mkdir paddle-open3d
cd paddle-open3d
sudo tar -zxvf paddle-open3d.tar.gz

# activate conda env
conda activate paddle-open3d
```
## How to run

  ```
  cd PaddleCFD/examples/aerodynamic_drag_pred/ppfno
  ```

    # Training dataset preprocess: .csv+.stl+.json -> .npy + .pdparams + .txt
    python trainDataPreprocess.py pre_input_path=/train_dataset pre_output_path=/train_dataset_processed process_mode=train

    # Inference dataset preprocess: .stl+.json -> .npy + .pdparams
    python inferenceDataPreprocess.py pre_input_path=/inference_dataset pre_output_path=/inference_dataset_processed bounds_dir=/train_dataset_processed process_mode=infer

    # Parallel training
    python -m paddle.distributed.launch --gpus=0,1 train.py train_input_path=/train_dataset_processed train_ratio=0.7 test_ratio=0.3 save_per_epoch=200 train_output_path=/train_output num_epochs=1000 finetuning_epochs=51

    # Offline inference
    python -m paddle.distributed.launch --gpus=0 inference.py reason_input_path=/inference_dataset_processed reason_output_path=/inference_output save_eval_results=false state=/checkpoints/GNOFNOGNO_all.pdparams pre_output_path=/train_dataset_processed

    # Start online inference service
    python -m paddle.distributed.launch --gpus=0 inference_server.py pd_path=/checkpoints/GNOFNOGNO_all.pdparams

    # Online inference
    curl -X POST "http://0.0.0.0:8087/api/v1/inference" -H "Content-Type: application/json" -d '{"reason_output_path":"/inference_output", "reason_input_path":"/inference_dataset_processed", "pre_output_path":"/train_dataset_processed"}'
